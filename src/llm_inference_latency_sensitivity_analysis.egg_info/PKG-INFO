Metadata-Version: 2.4
Name: llm-inference-latency-sensitivity-analysis
Version: 0.0.0a0
Summary: A kernel-level investigation of LLM latency sensitivity analysis under long-context inference on RTX 5070 GPUs.
Author-email: Sameer Wadkar <wadkar.sameer@gmail.com>
Classifier: Development Status :: 4 - Beta
Classifier: Intended Audience :: Developers
Classifier: Operating System :: OS Independent
Classifier: Programming Language :: Python
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.9
Classifier: Programming Language :: Python :: 3.10
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Classifier: Topic :: Software Development :: Libraries :: Python Modules
Requires-Python: >=3.9
Description-Content-Type: text/markdown
License-File: LICENCE
Requires-Dist: nvidia-ml-py3
Requires-Dist: transformers<5.0,>=4.40
Requires-Dist: accelerate>=0.30
Requires-Dist: matplotlib
Provides-Extra: dev
Requires-Dist: mypy[reports]; extra == "dev"
Requires-Dist: pytest; extra == "dev"
Requires-Dist: pytest-cov; extra == "dev"
Requires-Dist: ruff; extra == "dev"
Requires-Dist: uv; extra == "dev"
Requires-Dist: pre-commit; extra == "dev"
Requires-Dist: build; extra == "dev"
Requires-Dist: angreal; extra == "dev"
Dynamic: license-file

# Latency collapse analysis on RTX 5070


A systems-level, kernel-attributed analysis of LLM latency sensitivity under long-context inference on RTX 5070 GPUs.


## Development

* Clone this repository
* Requirements:
  * `angreal`
* `pip install angreal && angreal setup`


This project was generated using the [angreal python template](https://github.com/angreal/python) template.

## Install

#### 1. First install
```shell
 pip install -e .
```


#### 2. Install the appropriate version of Pytorch

Find what versions of CUDA drivers you have with
```shell

#[notice] To update, run: python.exe -m pip install --upgrade pip
(.venv) PS C:\Users\wadka\PycharmProjects\llm-inference-latency-sensitivity-analysis> nvidia-smi
Fri Dec 19 13:38:44 2025
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 577.05                 Driver Version: 577.05         CUDA Version: 12.9     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                  Driver-Model | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA GeForce RTX 5070 ...  WDDM  |   00000000:02:00.0  On |                  N/A |
| N/A   38C    P8              3W /   95W |     298MiB /  12227MiB |      0%      Default |
|                                         |                        |                  N/A |
+-----------------------------------------+------------------------+----------------------+

+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

```

This requires torch version below:

```shell
 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu128
```

```
python -c "import torch; print('torch', torch.__version__); print('cuda available', torch.cuda.is_available()); print('cuda runtime', torch.version.cuda); print('gpu', torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)"

##Output

torch 2.9.1+cu128
cuda available True
cuda runtime 12.8
gpu NVIDIA GeForce RTX 5070 Ti Laptop GPU

```

## Let's go

```shell
huggingface-cli login
#Login to HF
```
#### Sequence length sweep (batch size = 1):

```shell
latency-sensitivity sweep `
  --model Qwen/Qwen2.5-3B-Instruct `
  --dtype fp16 `
  --device cuda `
  --seq 128 `
  --batch-sizes 1,2,4,8,16,32,64 `
  --gen-tokens 32 `
  --warmup 3 `
  --reps 7 `
  --collapse-factor 2 `
  --out results/sweeps/qwen25_3b_fp16_grid_fixed_seq.csv
```

#### Batching sweep (fixed sequence length, increasing batch size):


```shell
latency-sensitivity sweep \
  --model Qwen/Qwen2.5-3B-Instruct \
  --dtype fp16 \
  --device cuda \
  --seq 128 \
  --batch-sizes 1,2,4,8,16,32,64 \
  --gen-tokens 32 \
  --warmup 3 \
  --reps 7 \
  --collapse-factor 2 \
  --out results/sweeps/qwen25_3b_fp16_grid_fixed_batch.csv
```

## [Full Article](./LATENCY_SENSITIVITY_ANALYSIS_ON_RTX_5070.md)
